{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../src')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hifigan_module import HiFiGanModuel\n",
    "\n",
    "hifigan_module = HiFiGanModuel.load_from_checkpoint('../models//hifigan_config1-epoch=969-val_avg_loss=0.2610.ckpt', map_location='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing weight norm...\n"
     ]
    }
   ],
   "source": [
    "generator = hifigan_module.generator\n",
    "generator.remove_weight_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.transforms import Resample\n",
    "from audio_processing import mel_spectrogram\n",
    "def get_item_hifi_gan(audiopath):\n",
    "    sampling_rate=22050\n",
    "    ori_sampling_rate=44100\n",
    "    resampler = Resample(\n",
    "        orig_freq=ori_sampling_rate,\n",
    "        new_freq=sampling_rate\n",
    "    )\n",
    "    audio, _ = torchaudio.load(audiopath)\n",
    "    if audio.size(0) !=1:\n",
    "        audio = torch.mean(audio, dim=0).unsqueeze(0)\n",
    "    audio = resampler(audio)\n",
    "    audio = torch.autograd.Variable(audio, requires_grad=False)\n",
    "    melspec = mel_spectrogram(\n",
    "        y=audio,\n",
    "        n_fft=1024,\n",
    "        num_mels=80,\n",
    "        sampling_rate=sampling_rate,\n",
    "        hop_size=256,\n",
    "        win_size=1024,\n",
    "        fmin=0.0,\n",
    "        fmax=11025.0,\n",
    "    )\n",
    "    mel_spec = torch.squeeze(melspec, 0)\n",
    "    return mel_spec.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from scipy.io.wavfile import write\n",
    "import os\n",
    "MAX_WAV_VALUE = 32768.0 \n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    sampling_rate=22050\n",
    "    mel = get_item_hifi_gan('4_3189.wav')\n",
    "    mel = mel.to('cuda:0')\n",
    "    y_g_hat = generator(mel.unsqueeze(0))\n",
    "    audio = y_g_hat.squeeze()\n",
    "    audio = audio * MAX_WAV_VALUE\n",
    "    audio = audio.cpu().numpy().astype('int16')\n",
    "\n",
    "    output_file = '4_3189_generated.wav'\n",
    "    write(output_file, sampling_rate, audio)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
